





import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
import seaborn as sns
warnings.filterwarnings('ignore')
pd.set_option('display.max_rows', 10000)
pd.set_option('display.max_columns', 10000)





data = pd.read_csv('user_profiles_for_ads.csv')


data.head()








data.shape





data.columns





data.info()





data.dtypes





data.describe().T





data.isnull().sum()





data.duplicated().sum()





plt.subplots(2, 2, figsize = (17 , 10))
plt.suptitle('Distribution of Key Demographic Variables')

plt.subplot(221)
plt.title('Age Distribution')
sns.countplot(x = 'Age', data = data, )

plt.subplot(222)
plt.title('Gender Distribution')
sns.countplot(x = 'Gender', data = data)

plt.subplot(223)
plt.title('Education Level Distribution')
sns.countplot(x = 'Education Level', data = data)

plt.subplot(224)
plt.title('Income Level Distribution')
sns.countplot(x = 'Income Level', data = data)

plt.show()





plt.subplots(1, 1, figsize = (17 , 5))
plt.suptitle('Device Usage Distribution')

plt.subplot(111)
sns.countplot(x = 'Device Usage', data = data)

plt.show()








plt.subplots(3, 2, figsize = (17 , 17))
plt.suptitle('User Online Behavior and Ad Interaction Metrics')

plt.subplot(321)
plt.title('Time Spent Online on Weekdays')
sns.histplot(x = 'Time Spent Online (hrs/weekday)', data = data, kde=True)

plt.subplot(322)
plt.title('Time Spent Online on Weekends')
sns.histplot(x = 'Time Spent Online (hrs/weekend)', data = data, kde=True)

plt.subplot(323)
plt.title('Likes and Reactions')
sns.histplot(x = 'Likes and Reactions', data = data, kde=True)

plt.subplot(324)
plt.title('Click-Through Rates (CTR)')
sns.histplot(x = 'Click-Through Rates (CTR)', data = data, kde=True)

plt.subplot(325)
plt.title('Conversion Rates')
sns.histplot(x = 'Conversion Rates', data = data, kde=True)

plt.subplot(326)
plt.title('Ad Interaction Time (sec)')
sns.histplot(x = 'Ad Interaction Time (sec)', data = data, kde=True)

plt.show()





from collections import Counter





# splitting the 'Top Interests' column and creating a list of all interests

interests_list = data['Top Interests'].str.split(', ').sum()


#interests_list


# counting the frequency of each interest

interest_counter = Counter(interests_list)


#interest_counter


#interest_counter.items()





# converting the counter object to a DataFrame for easier plotting

interests_df = pd.DataFrame(interest_counter.items(), columns = ['Interest', 'Frequency']).sort_values(by = 'Frequency', ascending = False)


interests_df








# plotting the most common interests

plt.figure(figsize=(12, 5))
sns.barplot(x = 'Frequency', y = 'Interest', data = interests_df.head(10), palette='coolwarm')
plt.title('Top 10 User Interests')
plt.xlabel('Frequency')
plt.ylabel('Interests')
plt.show()

















from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.cluster import KMeans





# selecting features for clustering

features = ['Age', 'Gender', 'Income Level', 'Time Spent Online (hrs/weekday)', 'Time Spent Online (hrs/weekend)', 'Likes and Reactions', 'Click-Through Rates (CTR)']

X = data[features]





# creating numerical and categorical pipelines

numeric_features = ['Time Spent Online (hrs/weekday)', 'Time Spent Online (hrs/weekend)', 'Likes and Reactions', 'Click-Through Rates (CTR)']

numeric_transformer = StandardScaler()

categorical_features = ['Age', 'Gender', 'Income Level']

categorical_transformer = OneHotEncoder()





preprocessor = ColumnTransformer(
    transformers = [
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ]
)

pipeline = Pipeline(steps = [('preprocessor', preprocessor),
                            ('cluster', KMeans(n_clusters = 5, random_state = 42))])

pipeline.fit(X)





cluster_labels = pipeline.named_steps['cluster'].labels_


data['Cluster'] = cluster_labels


data.head()








# computing the mean values of numerical features for each cluster

cluster_means = data.groupby('Cluster')[numeric_features].mean()


cluster_means





# computing the mode values of categorical features for each cluster

for feature in categorical_features:
    mode_series = data.groupby('Cluster')[feature].agg(lambda x : x.mode()[0])
    cluster_means[feature] = mode_series


cluster_means











data.head()






